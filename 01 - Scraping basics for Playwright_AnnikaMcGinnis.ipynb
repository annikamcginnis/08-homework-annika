{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping basics for Playwright\n",
    "\n",
    "This notebook is a combination of small scraping techniques along with how to use Playwright. Along with the class notes, the [scraping section](https://jonathansoma.com/everything/scraping/) on my Everything I Know site might be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import what you need to use Playwright, and start up a new browser to use for scraping. \n",
    "\n",
    "> If you end up opening a lot of Chromes/Chromiums, shutting down the Python kernel with the stop button is an easy way to make them go away! You'll have to re-run your notebook, but at least you won't have sixty icons in your dock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.async_api import async_playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = await browser.new_page()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping by class\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/columbia/interactive-scrape/by-class.html using their **class name**, printing out the title, subhead, and byline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response url='https://jonathansoma.com/columbia/interactive-scrape/by-class.html' request=<Request url='https://jonathansoma.com/columbia/interactive-scrape/by-class.html' method='GET'>>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await page.goto(\"https://jonathansoma.com/columbia/interactive-scrape/by-class.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = await page.content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html><html><head><script>\\n    const html = `\\n<h1 class=\"title\">How to Scrape Things</h1>\\n<h3 class=\"subhead\">Probably using Playwright</h3>\\n<p class=\"byline\">By Jonathan Soma</p>\\n`\\n\\nsetTimeout(() => {\\n    console.log(html)\\n    document.querySelector(\\'body\\').innerHTML = html\\n}, 250)</script>\\n</head><body>\\n<h1 class=\"title\">How to Scrape Things</h1>\\n<h3 class=\"subhead\">Probably using Playwright</h3>\\n<p class=\"byline\">By Jonathan Soma</p>\\n</body></html>'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup_doc = BeautifulSoup(html)\n",
    "html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping using a single tag\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/columbia/interactive-scrape/by-list.html, creating a dictionary out of the title, subhead, and byline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <script>\n",
      "   const html = `\n",
      "<h1 class=\"title\">How to Scrape Things</h1>\n",
      "<h3 class=\"subhead\">Probably using Playwright</h3>\n",
      "<p class=\"byline\">By Jonathan Soma</p>\n",
      "`\n",
      "\n",
      "setTimeout(() => {\n",
      "    console.log(html)\n",
      "    document.querySelector('body').innerHTML = html\n",
      "}, 250)\n",
      "  </script>\n",
      " </head>\n",
      " <body>\n",
      "  <h1 class=\"title\">\n",
      "   How to Scrape Things\n",
      "  </h1>\n",
      "  <h3 class=\"subhead\">\n",
      "   Probably using Playwright\n",
      "  </h3>\n",
      "  <p class=\"byline\">\n",
      "   By Jonathan Soma\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup_doc.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'How to Scrape Things', 'subhead': 'Probably using Playwright', 'byline': 'By Jonathan Soma'}\n"
     ]
    }
   ],
   "source": [
    "basic_scrape = {}\n",
    "\n",
    "title = soup_doc.find('h1', class_='title').string\n",
    "subhead = soup_doc.find('h3', class_='subhead').string\n",
    "byline = soup_doc.find('p', class_='byline').string\n",
    "\n",
    "basic_scrape['title'] = title\n",
    "basic_scrape['subhead'] = subhead\n",
    "basic_scrape['byline'] = byline\n",
    "\n",
    "print(basic_scrape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waiting\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/columbia/interactive-scrape/by-tag-wait.html just like you above, but use  **wait_for** to wait for the text \"Everything has shown up\" to show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response url='https://jonathansoma.com/columbia/interactive-scrape/by-tag-wait.html' request=<Request url='https://jonathansoma.com/columbia/interactive-scrape/by-tag-wait.html' method='GET'>>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await page.goto(\"https://jonathansoma.com/columbia/interactive-scrape/by-tag-wait.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<JSHandle preview=JSHandle@node>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await page.wait_for_selector(\"text='Everything has shown up'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = await page.content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html><html><head><script>\\n    const html = `<p>How to Scrape Things</p>\\n<p>Probably using Playwright</p>\\n<p>By Jonathan Soma</p>\\n<p>Everything has shown up</p> \\n`\\n\\nlet pieces = html.split(\"\\\\n\")\\n\\nfunction addPiece() {\\n    document.querySelector(\\'body\\').innerHTML = document.querySelector(\\'body\\').innerHTML + pieces.shift()\\n    if(pieces.length > 0) {\\n        setTimeout(addPiece, 250)\\n    } else {\\n        setTimeout(() => {\\n            document.querySelector(\\'body\\').innerHTML = \"\"\\n            pieces = html.split(\"\\\\n\")\\n            setTimeout(addPiece, 1000)\\n        }, 2000)\\n    }\\n}\\n\\nsetTimeout(addPiece, 250)\\n</script>\\n</head><body>\\n\\n<p>How to Scrape Things</p><p>Probably using Playwright</p><p>By Jonathan Soma</p><p>Everything has shown up</p> </body></html>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup_doc = BeautifulSoup(html)\n",
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <script>\n",
      "   const html = `<p>How to Scrape Things</p>\n",
      "<p>Probably using Playwright</p>\n",
      "<p>By Jonathan Soma</p>\n",
      "<p>Everything has shown up</p> \n",
      "`\n",
      "\n",
      "let pieces = html.split(\"\\n\")\n",
      "\n",
      "function addPiece() {\n",
      "    document.querySelector('body').innerHTML = document.querySelector('body').innerHTML + pieces.shift()\n",
      "    if(pieces.length > 0) {\n",
      "        setTimeout(addPiece, 250)\n",
      "    } else {\n",
      "        setTimeout(() => {\n",
      "            document.querySelector('body').innerHTML = \"\"\n",
      "            pieces = html.split(\"\\n\")\n",
      "            setTimeout(addPiece, 1000)\n",
      "        }, 2000)\n",
      "    }\n",
      "}\n",
      "\n",
      "setTimeout(addPiece, 250)\n",
      "  </script>\n",
      " </head>\n",
      " <body>\n",
      "  <p>\n",
      "   How to Scrape Things\n",
      "  </p>\n",
      "  <p>\n",
      "   Probably using Playwright\n",
      "  </p>\n",
      "  <p>\n",
      "   By Jonathan Soma\n",
      "  </p>\n",
      "  <p>\n",
      "   Everything has shown up\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup_doc.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nHow to Scrape ThingsProbably using PlaywrightBy Jonathan SomaEverything has shown up '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup_doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to Scrape Things\n",
      "Probably using Playwright\n",
      "By Jonathan Soma\n",
      "Everything has shown up\n"
     ]
    }
   ],
   "source": [
    "text = soup_doc.find_all('p')\n",
    "for line in text:\n",
    "    print(line.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forms\n",
    "\n",
    "Display the content of the `h1` tag on http://jonathansoma.com/columbia/interactive-scrape/inputs.html. You'll need to follow the instructions to complete the form first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response url='https://jonathansoma.com/columbia/interactive-scrape/inputs.html' request=<Request url='https://jonathansoma.com/columbia/interactive-scrape/inputs.html' method='GET'>>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await page.goto(\"https://jonathansoma.com/columbia/interactive-scrape/inputs.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Open']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await page.locator(\"select\").select_option('Open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "await page.get_by_placeholder(\"write cat in here\").fill(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "await page.get_by_role(\"button\", name=\"Click me\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping a single table row\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/columbia/interactive-scrape/single-table-row.html, creating a dictionary out of the title, subhead, and byline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response url='https://jonathansoma.com/columbia/interactive-scrape/single-table-row.html' request=<Request url='https://jonathansoma.com/columbia/interactive-scrape/single-table-row.html' method='GET'>>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await page.goto(\"https://jonathansoma.com/columbia/interactive-scrape/single-table-row.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <script>\n",
      "   const html = `<table>\n",
      "  <tr>\n",
      "    <td>How to Scrape Things</td>\n",
      "    <td>Probably using Playwright</td>\n",
      "    <td>By Jonathan Soma</td>\n",
      "  </tr>\n",
      "</table>\n",
      "`\n",
      "\n",
      "setTimeout(() => {\n",
      "    console.log(html)\n",
      "    document.querySelector('body').innerHTML = html\n",
      "}, 250)\n",
      "  </script>\n",
      " </head>\n",
      " <body>\n",
      "  <table>\n",
      "   <tbody>\n",
      "    <tr>\n",
      "     <td>\n",
      "      How to Scrape Things\n",
      "     </td>\n",
      "     <td>\n",
      "      Probably using Playwright\n",
      "     </td>\n",
      "     <td>\n",
      "      By Jonathan Soma\n",
      "     </td>\n",
      "    </tr>\n",
      "   </tbody>\n",
      "  </table>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html = await page.content()\n",
    "soup_doc = BeautifulSoup(html)\n",
    "print(soup_doc.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'How to Scrape Things',\n",
       " 'subhead': 'Probably using Playwright',\n",
       " 'byline': 'By Jonathan Soma'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = soup_doc.find_all('td')\n",
    "\n",
    "soma_scrape = {}\n",
    "soma_scrape['title'] = text[0].text\n",
    "soma_scrape['subhead'] = text[1].text\n",
    "soma_scrape['byline'] = text[2].text\n",
    "soma_scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving into a dictionary\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/columbia/interactive-scrape/single-table-row.html, saving the title, subhead, and byline into a single dictionary called `book`.\n",
    "\n",
    "> Don't use pandas for this one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'How to Scrape Things',\n",
       " 'subhead': 'Probably using Playwright',\n",
       " 'byline': 'By Jonathan Soma'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book = {}\n",
    "book['title'] = text[0].text\n",
    "book['subhead'] = text[1].text\n",
    "book['byline'] = text[2].text\n",
    "book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping multiple table rows\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/columbia/interactive-scrape/multiple-table-rows.html, creating a list of dictionaries. Convert to a pandas dataframe with `pd.json_normalize`. Save it as `output.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response url='https://jonathansoma.com/columbia/interactive-scrape/multiple-table-rows.html' request=<Request url='https://jonathansoma.com/columbia/interactive-scrape/multiple-table-rows.html' method='GET'>>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await page.goto(\"https://jonathansoma.com/columbia/interactive-scrape/multiple-table-rows.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <script>\n",
      "   const html = `<table>\n",
      "  <tr>\n",
      "    <td>How to Scrape Things</td>\n",
      "    <td>Probably using Playwright</td>\n",
      "    <td>By Jonathan Soma</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>How to Scrape Many Things</td>\n",
      "    <td>But, Is It Even Possible?</td>\n",
      "    <td>By Sonathan Joma</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>The End of Scraping</td>\n",
      "    <td>Let's All Use CSV Files</td>\n",
      "    <td>By Amos Nathanos</td>\n",
      "  </tr>\n",
      "</table>\n",
      "`\n",
      "\n",
      "setTimeout(() => {\n",
      "    document.querySelector('body').innerHTML = html\n",
      "}, 250)\n",
      "  </script>\n",
      " </head>\n",
      " <body>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html = await page.content()\n",
    "soup_doc = BeautifulSoup(html)\n",
    "print(soup_doc.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = soup_doc.find_all('tr')\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "for row in rows:\n",
    "    scraping_info = {}\n",
    "    \n",
    "    title = row.find_all('td')[0].string\n",
    "    scraping_info['title'] = title\n",
    "\n",
    "    musing = row.find_all('td')[1].string\n",
    "    scraping_info['musing'] = musing\n",
    "\n",
    "    byline = row.find_all('td')[2].string\n",
    "    scraping_info['byline'] = byline\n",
    "\n",
    "    all_rows.append(scraping_info)\n",
    "\n",
    "all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.json_normalize(all_rows)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"scraping.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping an actual table\n",
    "\n",
    "Scrape the content at http://jonathansoma.com/columbia/interactive-scrape/the-actual-table.html using pandas' HTML reading function. Save it as `output.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response url='https://jonathansoma.com/columbia/interactive-scrape/the-actual-table.html' request=<Request url='https://jonathansoma.com/columbia/interactive-scrape/the-actual-table.html' method='GET'>>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await page.goto(\"https://jonathansoma.com/columbia/interactive-scrape/the-actual-table.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <script>\n",
      "   const html = `<table id=\"booklist\">\n",
      "  <tr>\n",
      "    <td>How to Scrape Things</td>\n",
      "    <td>Probably using Playwright</td>\n",
      "    <td>By Jonathan Soma</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>How to Scrape Many Things</td>\n",
      "    <td>But, Is It Even Possible?</td>\n",
      "    <td>By Sonathan Joma</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>The End of Scraping</td>\n",
      "    <td>Let's All Use CSV Files</td>\n",
      "    <td>By Amos Nathanos</td>\n",
      "  </tr>\n",
      "</table>\n",
      "`\n",
      "\n",
      "setTimeout(() => {\n",
      "    console.log(html)\n",
      "    document.querySelector('body').innerHTML = html\n",
      "}, 250)\n",
      "  </script>\n",
      " </head>\n",
      " <body>\n",
      "  <table id=\"booklist\">\n",
      "   <tbody>\n",
      "    <tr>\n",
      "     <td>\n",
      "      How to Scrape Things\n",
      "     </td>\n",
      "     <td>\n",
      "      Probably using Playwright\n",
      "     </td>\n",
      "     <td>\n",
      "      By Jonathan Soma\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      How to Scrape Many Things\n",
      "     </td>\n",
      "     <td>\n",
      "      But, Is It Even Possible?\n",
      "     </td>\n",
      "     <td>\n",
      "      By Sonathan Joma\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      The End of Scraping\n",
      "     </td>\n",
      "     <td>\n",
      "      Let's All Use CSV Files\n",
      "     </td>\n",
      "     <td>\n",
      "      By Amos Nathanos\n",
      "     </td>\n",
      "    </tr>\n",
      "   </tbody>\n",
      "  </table>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html = await page.content()\n",
    "soup_doc = BeautifulSoup(html)\n",
    "print(soup_doc.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to Scrape Things</td>\n",
       "      <td>Probably using Playwright</td>\n",
       "      <td>By Jonathan Soma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to Scrape Many Things</td>\n",
       "      <td>But, Is It Even Possible?</td>\n",
       "      <td>By Sonathan Joma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The End of Scraping</td>\n",
       "      <td>Let's All Use CSV Files</td>\n",
       "      <td>By Amos Nathanos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0                          1                 2\n",
       "0       How to Scrape Things  Probably using Playwright  By Jonathan Soma\n",
       "1  How to Scrape Many Things  But, Is It Even Possible?  By Sonathan Joma\n",
       "2        The End of Scraping    Let's All Use CSV Files  By Amos Nathanos"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "tables = pd.read_html(StringIO(html))\n",
    "tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[0].to_csv(\"scraping2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `html.parser` vs `html5lib`\n",
    "\n",
    "Here is some good HTML:\n",
    "\n",
    "```python\n",
    "html_good = \"\"\"\n",
    "<h1>This is a title</h1>\n",
    "<h2>This is a subhead</h2>\n",
    "<p>This is a paragraph</p>\n",
    "<p>This is another paragraph</p>\n",
    "\"\"\"\n",
    "\n",
    "Here is some bad HTML:\n",
    "    \n",
    "html_bad = \"\"\"\n",
    "<h1>This is a title\n",
    "<h2>This is a subhead\n",
    "<p>This is a paragraph\n",
    "<p>This is another paragraph\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "When you're using BeautifulSoup, you can use different parsers, including `html.parser`, `html5lib` and `lxml`. Try both the good HTML and bad HTML with each parser and use `print(soup_doc.prettify())` to view the difference.\n",
    "\n",
    "What is different about each one?\n",
    "\n",
    "> You'll need to `pip install` for both html5lib and lxml. Since you aren't important them, they're coming from BeautifulSoup, you'll need to do **Kernel > Restart** and run from the top after installing to have them work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: html5lib in /Users/annikamcginnis/.pyenv/versions/3.12.7/lib/python3.12/site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in /Users/annikamcginnis/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /Users/annikamcginnis/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from html5lib) (0.5.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /Users/annikamcginnis/.pyenv/versions/3.12.7/lib/python3.12/site-packages (4.9.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_good = \"\"\"\n",
    "<h1>This is a title</h1>\n",
    "<h2>This is a subhead</h2>\n",
    "<p>This is a paragraph</p>\n",
    "<p>This is another paragraph</p>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_bad = \"\"\"\n",
    "<h1>This is a title\n",
    "<h2>This is a subhead\n",
    "<p>This is a paragraph\n",
    "<p>This is another paragraph\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   This is a title\n",
      "  </h1>\n",
      "  <h2>\n",
      "   This is a subhead\n",
      "  </h2>\n",
      "  <p>\n",
      "   This is a paragraph\n",
      "  </p>\n",
      "  <p>\n",
      "   This is another paragraph\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup_doc = BeautifulSoup(html_good, \"html5lib\")\n",
    "print(soup_doc.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <h1>\n",
      "   This is a title\n",
      "  </h1>\n",
      "  <h2>\n",
      "   This is a subhead\n",
      "  </h2>\n",
      "  <p>\n",
      "   This is a paragraph\n",
      "  </p>\n",
      "  <p>\n",
      "   This is another paragraph\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soup_doc = BeautifulSoup(html_good, \"lxml\")\n",
    "print(soup_doc.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>\n",
      " This is a title\n",
      "</h1>\n",
      "<h2>\n",
      " This is a subhead\n",
      "</h2>\n",
      "<p>\n",
      " This is a paragraph\n",
      "</p>\n",
      "<p>\n",
      " This is another paragraph\n",
      "</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soup_doc = BeautifulSoup(html_good, \"html.parser\")\n",
    "print(soup_doc.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      " </head>\n",
      " <body>\n",
      "  <h1>\n",
      "   This is a title\n",
      "  </h1>\n",
      "  <h2>\n",
      "   This is a subhead\n",
      "   <p>\n",
      "    This is a paragraph\n",
      "   </p>\n",
      "   <p>\n",
      "    This is another paragraph\n",
      "   </p>\n",
      "  </h2>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soup_doc = BeautifulSoup(html_bad, \"html5lib\")\n",
    "print(soup_doc.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <h1>\n",
      "   This is a title\n",
      "   <h2>\n",
      "    This is a subhead\n",
      "   </h2>\n",
      "  </h1>\n",
      "  <p>\n",
      "   This is a paragraph\n",
      "  </p>\n",
      "  <p>\n",
      "   This is another paragraph\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soup_doc = BeautifulSoup(html_bad, \"lxml\")\n",
    "print(soup_doc.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>\n",
      " This is a title\n",
      " <h2>\n",
      "  This is a subhead\n",
      "  <p>\n",
      "   This is a paragraph\n",
      "   <p>\n",
      "    This is another paragraph\n",
      "   </p>\n",
      "  </p>\n",
      " </h2>\n",
      "</h1>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soup_doc = BeautifulSoup(html_bad, \"html.parser\")\n",
    "print(soup_doc.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
